{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cm4wTH5NBwJY"
      },
      "source": [
        "### **Import libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CyWfbnL18WIz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZscjHsjm6-r"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "# from https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking\n",
        "torch.backends.cudnn.deterministic = True            # force cuda to use deterministic algorithm\n",
        "torch.backends.cudnn.benchmark = False               # disable cuda feature of selecting the fastest algorith\n",
        "                                                     # (it can be non-deterministic and affect repeatability)\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import copy\n",
        "import types\n",
        "\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1mDffoOB2Ir"
      },
      "outputs": [],
      "source": [
        "# Choosing the device to work with\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4FLFM0rJU_n"
      },
      "outputs": [],
      "source": [
        "# control random number generation for repeatability\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChCFAAvM1rd"
      },
      "source": [
        "## **Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-lrLcsZNCKR"
      },
      "outputs": [],
      "source": [
        "# Set variable to activate or deactivate part of the code\n",
        "do_mnist_data_analysis = 0; #(0)1: (De)activate code to show analysis done on MNIST data\n",
        "do_cifar_data_analysis = 0; #(0)1: (De)activate code to show analysis done on CIFAR data\n",
        "run_LeNet_mnist = 1;        #(0)1: (De)activate code to execute LeNet on MNIST data\n",
        "run_ResNet_cifar = 0;       #(0)1: (De)activate code to execute ResNet on CIFAR data\n",
        "\n",
        "# Hyperparameters for training on MNIST\n",
        "epochs_mnist = 30  # Number of training epochs\n",
        "lr_mnist = 0.01    # Learning rate for the optimizer\n",
        "\n",
        "# Hyperparameters for training on CIFAR\n",
        "epochs_cifar = 150         # Number of training epochs\n",
        "lr_cifar = 0.1              # Learning rate for the optimizer\n",
        "\n",
        "# Hyperparameter for SNIP\n",
        "sparsities_mnist = [0, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.995, 0.999] # Sparsities values for LeNet5 architecture employed for mnist\n",
        "sparsities_cifar = [0, 0.25, 0.5, 0.75] # sparsities values for ResNet18 architecture employed for cifar-10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECn-7rAa7NZk"
      },
      "source": [
        "### Values indicated in the assignment:\n",
        "\n",
        "\n",
        "1. Hyperparameters for training on MNIST\n",
        "   * epochs_mnist = 30  \n",
        "   * lr_mnist = 0.01    \n",
        "   * sparsities_mnist = $[0, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.995, 0.999]$\n",
        "\n",
        "\n",
        "2.   Hyperparameters for training on CIFAR\n",
        "    * epochs_cifar = 150   \n",
        "    * lr_cifar = 0.1          \n",
        "    * sparsities_cifar = $[0, 0.25, 0.5, 0.75]$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbpyScdvFhCb"
      },
      "source": [
        "# **Datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbbDtsnN4JnM"
      },
      "source": [
        "## MNIST"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pePIAu62UnFc"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Load MNIST dataset\n",
        "  transform = transforms.ToTensor()\n",
        "  trainval_mnist = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "  test_mnist = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzTnxhtFXTFV"
      },
      "source": [
        "### Dataset Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Mt3KlOSU-lI"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # Dataset size\n",
        "  print(f\"Training + Validation Set Size: {len(trainval_mnist)} images\")\n",
        "  print(f\"Test Set Size: {len(test_mnist)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8fFooLdBoID"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # check if there are nan in the dataset\n",
        "  print(trainval_mnist.data.isnan().any())\n",
        "  print(test_mnist.data.isnan().any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnanSAIFjRft"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # create a visualization of a MNIST plot with pixels values\n",
        "  image, label = trainval_mnist[1] # extract both image and label\n",
        "\n",
        "  # Plot the image with pixel values\n",
        "  plt.figure(figsize=(10, 10))\n",
        "  plt.imshow(image.squeeze(), cmap='gray') # use image.squeeze() to remove unnecessary dimensions\n",
        "\n",
        "  # Loop through each pixel and annotate its value\n",
        "  for i in range(image.shape[1]): # image.shape[1] represents the height (28 pixels)\n",
        "      for j in range(image.shape[2]): # image.shape[2] represents the width (28 pixels)\n",
        "          # Convert the tensor element to a Python float before formatting\n",
        "          pixel_value = image[0, i, j].item()*255  # Access the pixel value at (0, i, j) for a single-channel image\n",
        "          plt.text(j, i, f'{pixel_value:.0f}', ha='center', va='center', color='red', fontsize=8)\n",
        "\n",
        "  # Remove the axis\n",
        "  plt.axis('off')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsKthO_iVNXJ"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # Studying resolutions\n",
        "  trainval_resolutions = [img.shape[1:] for img, _ in trainval_mnist]\n",
        "  test_resolutions = [img.shape[1:] for img, _ in test_mnist]\n",
        "  resolutions = trainval_resolutions + test_resolutions\n",
        "  unique_resolutions = set(resolutions)\n",
        "  print(\"Unique resolutions:\", unique_resolutions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vdd-0E4q0RDi"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # Define figure size and grid layout\n",
        "  fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(8, 8))\n",
        "\n",
        "  # Create a dictionary to store 10 images per class\n",
        "  class_images = {cls: [] for cls in range(10)}  # 10 labels in MNIST\n",
        "\n",
        "  # Loop through the dataset to collect 10 images per class\n",
        "  for img, label in test_mnist:\n",
        "      if len(class_images[label]) < 10:  # Check if we have collected 10 images for this class\n",
        "          class_images[label].append(img)\n",
        "\n",
        "      # Stop once we've collected 10 images for each class\n",
        "      if all(len(images) == 10 for images in class_images.values()):\n",
        "          break\n",
        "\n",
        "  # Loop through the axes and plot images for each class\n",
        "  for i, (cls, images) in enumerate(class_images.items()):\n",
        "      # Display the class name once at the top of each column\n",
        "      ax = axes[0, i]  # Top row, each column corresponds to a class\n",
        "      ax.set_title(\"class: \"+ str(cls), fontsize=12)  # Set the class name as title\n",
        "      ax.axis('off')  # Hide axis for the title cell\n",
        "\n",
        "      # Loop through the images for this class and plot them in the column\n",
        "      for j, img in enumerate(images):\n",
        "          ax = axes[j, i]  # Set the row for the images (starting from row 1)\n",
        "          npimg = img.numpy()  # Convert to numpy\n",
        "          ax.imshow(npimg.squeeze(), cmap=\"gray\")  # Display image with the correct channel order\n",
        "          ax.axis('off')  # Hide axis for better visualization\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnTmEXw6tTc1"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # plot pixel vs pixel frequency for MNIST trainval dataset\n",
        "  all_pixels = []\n",
        "\n",
        "  for image,label in trainval_mnist:\n",
        "    image = image.numpy().flatten()\n",
        "    all_pixels.extend(image)\n",
        "\n",
        "  all_pixels = np.array(all_pixels)\n",
        "  all_pixels = (all_pixels*255).astype(int) #convert pixels value to the range [0 255]\n",
        "  pixel_values, pixel_counts = np.unique(all_pixels, return_counts=True)\n",
        "\n",
        "  #create figure\n",
        "  from matplotlib.ticker import ScalarFormatter\n",
        "  fig, axs = plt.subplots(1, 2, figsize=(20, 6))\n",
        "  axs[0].bar(pixel_values, pixel_counts, color='royalblue', width = 3)\n",
        "  axs[0].set_xlabel('Pixel Values', fontsize=14, fontweight='bold')\n",
        "  axs[0].set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
        "  axs[0].set_title('Frequency of Pixel Values in Train+Val MNIST Dataset', fontsize=16, fontweight='bold')\n",
        "  axs[0].grid(True)\n",
        "  axs[0].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
        "  axs[0].ticklabel_format(style='plain', axis='y')\n",
        "\n",
        "  axs[1].bar(pixel_values, pixel_counts, color='royalblue', width = 3)\n",
        "  axs[1].set_xlabel('Pixel Values', fontsize=14, fontweight='bold')\n",
        "  axs[1].set_ylabel('Frequency', fontsize=14, fontweight='bold')\n",
        "  axs[1].set_title('Frequency of Pixel Values in Train+Val MNIST Dataset (Zoomed)', fontsize=16, fontweight='bold')\n",
        "  axs[1].grid(True)\n",
        "  axs[1].set_ylim(0,2000000)\n",
        "  axs[1].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
        "  axs[1].ticklabel_format(style='plain', axis='y')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVvtVThzxsXY"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # create graph with average pixel distribution for each sample in each class\n",
        "  from collections import defaultdict\n",
        "\n",
        "  # Create a dictionary to store the average pixel values for each class\n",
        "  class_avg_pixel_values = defaultdict(list)\n",
        "\n",
        "  # Iterate over the dataset\n",
        "  for image, label in trainval_mnist:\n",
        "      # Calculate the average pixel value for the current image\n",
        "      avg_pixel_value = image.numpy().mean()\n",
        "\n",
        "      # Append the average pixel value to the corresponding class list\n",
        "      class_avg_pixel_values[label].append(avg_pixel_value)\n",
        "\n",
        "  # Convert the dictionary values to numpy arrays for easier manipulation\n",
        "  for class_label in class_avg_pixel_values:\n",
        "      class_avg_pixel_values[class_label] = np.array(class_avg_pixel_values[class_label])\n",
        "\n",
        "\n",
        "  # Plot the average pixel values for each class as histograms\n",
        "  fig, axs = plt.subplots(2, 5, figsize=(20, 10))\n",
        "\n",
        "  # Iterate through each class and plot the average pixel values as a histogram\n",
        "  for class_label, avg_values in class_avg_pixel_values.items():\n",
        "      row = class_label // 5\n",
        "      col = class_label % 5\n",
        "      axs[row, col].hist(avg_values*255, bins=30, color='royalblue', alpha=0.7, width=1)\n",
        "      axs[row, col].set_title(f'Class {class_label}')\n",
        "      axs[row, col].set_xlabel('Average Pixel Value')\n",
        "      axs[row, col].set_ylabel('Frequency')\n",
        "      axs[row, col].grid(True)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kwiLmQPZ4XR5"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  def select_images_from_class(dataset, desired_class, num_images):\n",
        "      # Filter images by the desired class\n",
        "      class_images = [(idx, image, label) for idx, (image, label) in enumerate(dataset) if label == desired_class]\n",
        "\n",
        "      # Select the specified number of images from the desired class\n",
        "      new_var = random.sample\n",
        "      selected_images = new_var(class_images, num_images)\n",
        "      return selected_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LYEhl4183quq"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  desired_class = 4\n",
        "  selected_images = select_images_from_class(trainval_mnist, desired_class, num_images=10)\n",
        "\n",
        "  # Plot the selected images\n",
        "  fig, axs = plt.subplots(2, 5, figsize=(10, 8))\n",
        "\n",
        "  for i, (image_id, image, label) in enumerate(selected_images):\n",
        "      row = i // 5\n",
        "      col = i % 5\n",
        "      axs[row, col].imshow(image.squeeze(), cmap='gray')\n",
        "      axs[row, col].set_title(f'ID: {image_id}')\n",
        "      axs[row, col].axis('off')\n",
        "\n",
        "  #plt.suptitle(f'10 Images from Class {desired_class}', fontsize=16, fontweight='bold')\n",
        "  plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EGpNx5x5P6L"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # Before computing class frequency in each dataset, split the in trainig | validation | test set\n",
        "  val_ratio_mnist = 0.1\n",
        "  val_size_mnist = int(val_ratio_mnist*len(trainval_mnist))\n",
        "  train_mnist, val_mnist = data.random_split(trainval_mnist, [len(trainval_mnist) - val_size_mnist,\n",
        "                                                      val_size_mnist])\n",
        "  print(f\"Training Set Size: {len(train_mnist)} images\")\n",
        "  print(f\"Validation Set Size: {len(val_mnist)} images\")\n",
        "  print(f\"Test Set Size: {len(test_mnist)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPw4umD1H7E3"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # compute the class frequency for the 3 dataset\n",
        "  # Function to compute class frequency\n",
        "  def compute_class_frequencies(dataset):\n",
        "      labels = np.array([label for _, label in dataset])  # Extract labels\n",
        "      label_counts = np.zeros(10, dtype=int)  # Array to store class counts\n",
        "      for label in labels:\n",
        "          label_counts[label] += 1  # Count occurrences\n",
        "      return label_counts\n",
        "\n",
        "  #class frequency\n",
        "  train_counts = compute_class_frequencies(train_mnist)\n",
        "  val_counts =  compute_class_frequencies(val_mnist)\n",
        "  test_counts = compute_class_frequencies(test_mnist)\n",
        "\n",
        "  # Create a 1-row, 3-column subplot\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(14, 6))\n",
        "\n",
        "  # Plot histogram for Train  Dataset\n",
        "  bars_train = axes[0].bar(range(10), train_counts, tick_label=range(10), color='royalblue')\n",
        "  axes[0].set_xlabel('Class')\n",
        "  axes[0].set_ylabel('Frequency')\n",
        "  axes[0].set_title('Class Frequency in MNIST Train Dataset')\n",
        "  axes[0].set_xticklabels(range(10), rotation=0)\n",
        "\n",
        "  # Add values on top of each bar for  Validation Dataset\n",
        "  for bar in bars_train:\n",
        "      height = bar.get_height()\n",
        "      axes[0].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  # Plot histogram for Validation Dataset\n",
        "  bars_val = axes[1].bar(range(10), val_counts, tick_label=range(10), color='orange')\n",
        "  axes[1].set_xlabel('Class')\n",
        "  axes[1].set_ylabel('Frequency')\n",
        "  axes[1].set_title('Class Frequency in MNIST Validation Dataset')\n",
        "  axes[1].set_xticklabels(range(10), rotation=0)\n",
        "\n",
        "  # Add values on top of each bar for Test Dataset\n",
        "  for bar in bars_val:\n",
        "      height = bar.get_height()\n",
        "      axes[1].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  # Plot histogram for Test Dataset\n",
        "  bars_test = axes[2].bar(range(10), test_counts, tick_label=range(10), color='seagreen')\n",
        "  axes[2].set_xlabel('Class')\n",
        "  axes[2].set_ylabel('Frequency')\n",
        "  axes[2].set_title('Class Frequency in MNIST Test Dataset')\n",
        "  axes[2].set_xticklabels(range(10), rotation=0)\n",
        "\n",
        "  # Add values on top of each bar for Test Dataset\n",
        "  for bar in bars_test:\n",
        "      height = bar.get_height()\n",
        "      axes[2].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFy-C1vuI7dw"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  #compute the ratio between each class in the Train, Val and Test dataset vs the highest frequency class\n",
        "  #find the highest frequency\n",
        "  highest_frequency_train = max(train_counts)\n",
        "  #coumpute the ratio for each class\n",
        "  ratios_train = train_counts / highest_frequency_train\n",
        "\n",
        "  #find the highest frequency\n",
        "  highest_frequency_val = max(val_counts)\n",
        "  #coumpute the ratio for each class\n",
        "  ratios_val = val_counts / highest_frequency_val\n",
        "\n",
        "  #find the highest frequency\n",
        "  highest_frequency_test = max(test_counts)\n",
        "  #coumpute the ratio for each class\n",
        "  ratios_test = test_counts / highest_frequency_test\n",
        "\n",
        "  ratios_tot = {\n",
        "      'Class': range(10),\n",
        "      'train': ratios_train,\n",
        "      'val': ratios_val,\n",
        "      'test': ratios_test\n",
        "  }\n",
        "\n",
        "  df = pd.DataFrame(ratios_tot)\n",
        "  print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uuq81FeIJHnQ"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # make a plot to compare the three distributions\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(ratios_train, label='Train', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_val, label='Val', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_test, label='Test', linestyle='--', marker='o')\n",
        "  plt.xlabel('Class')\n",
        "  plt.ylabel('Ratio vs higher frequency class in each dataset')\n",
        "  plt.title('Class ratio in Train | Val | Test Datasets')\n",
        "  plt.xticks(range(len(ratios_train)))\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_train):\n",
        "      plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_val):\n",
        "      plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Test dataset\n",
        "  for i, value in enumerate(ratios_test):\n",
        "      plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLWMP9m0JPC4"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # do the ratio vs the total number of samples for each class in Train,Val and test Dataset\n",
        "  total_samples_train = np.sum(train_counts)\n",
        "  ratios_train_total = train_counts / total_samples_train\n",
        "\n",
        "  total_samples_val = np.sum(val_counts)\n",
        "  ratios_val_total = val_counts / total_samples_val\n",
        "\n",
        "  total_samples_test = np.sum(test_counts)\n",
        "  ratios_test_total = test_counts / total_samples_test\n",
        "\n",
        "  ratios_total = {\n",
        "      'Class': range(10),\n",
        "      'train': ratios_train_total,\n",
        "      'val': ratios_val_total,\n",
        "      'test': ratios_test_total\n",
        "  }\n",
        "  df = pd.DataFrame(ratios_total)\n",
        "  print(df)\n",
        "  #check print total_samples_train\n",
        "  print(f'Total samples in Train Dataset: {total_samples_train}')\n",
        "  #check print total_samples_train\n",
        "  print(f'Total samples in Validation Dataset: {total_samples_val}')\n",
        "  #check print total_samples_test\n",
        "  print(f'Total samples in Test Dataset: {total_samples_test}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jl8ObDhjJTxv"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # make a plot to compare ratios_test_total vs ratios_train_total ans ratios_val_total\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(ratios_train_total, label='Train set', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_val_total, label='Validation set', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_test_total, label='Test set', linestyle='--', marker='o')\n",
        "  plt.xlabel('Class')\n",
        "  plt.ylabel('Ratio vs total #samples in each dataset')\n",
        "  plt.title('Class ratio in Train | Val | Test Datasets')\n",
        "  plt.xticks(range(len(ratios_train_total)))\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_train_total):\n",
        "    plt.text(i, value, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_val_total):\n",
        "    plt.text(i, value, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Test dataset\n",
        "  for i, value in enumerate(ratios_test_total):\n",
        "    plt.text(i, value, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PiyfCXIxnxNc"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # compute mean and std deviation for the solely training set\n",
        "  imgs_mnist = torch.stack([img for img, _ in train_mnist])\n",
        "  mean_mnist = imgs_mnist.mean(dim=(0, 2, 3))\n",
        "  std_mnist = imgs_mnist.std(dim=(0, 2, 3))\n",
        "  print(f\"Mean Train: {mean_mnist}\")\n",
        "  print(f\"Std dev Train: {std_mnist}\")\n",
        "\n",
        "  imgs_mnist = torch.stack([img for img, _ in trainval_mnist])\n",
        "  mean_mnist = imgs_mnist.mean(dim=(0, 2, 3))\n",
        "  std_mnist = imgs_mnist.std(dim=(0, 2, 3))\n",
        "  print(f\"Mean Train+Val: {mean_mnist}\")\n",
        "  print(f\"Std dev Train+Val: {std_mnist}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZqsDRLOn6CW"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # Function to compute class frequency\n",
        "  def compute_class_frequencies(dataset):\n",
        "      labels = np.array([label for _, label in dataset])  # Extract labels\n",
        "      label_counts = np.zeros(10, dtype=int)  # Array to store class counts\n",
        "      for label in labels:\n",
        "          label_counts[label] += 1  # Count occurrences\n",
        "      return label_counts\n",
        "\n",
        "  # Compute class frequencies for both datasets\n",
        "  trainval_counts = compute_class_frequencies(trainval_mnist)\n",
        "  test_counts = compute_class_frequencies(test_mnist)\n",
        "\n",
        "  # Create a 1-row, 2-column subplot\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "  # Plot histogram for Train + Validation Dataset\n",
        "  bars_trainval = axes[0].bar(range(10), trainval_counts, tick_label=range(10), color='royalblue')\n",
        "  axes[0].set_xlabel('Class')\n",
        "  axes[0].set_ylabel('Frequency')\n",
        "  axes[0].set_title('Class Frequency in MNIST Train+Val Dataset')\n",
        "  axes[0].set_xticklabels(range(10), rotation=0)\n",
        "\n",
        "  # Add values on top of each bar for Train + Validation Dataset\n",
        "  for bar in bars_trainval:\n",
        "      height = bar.get_height()\n",
        "      axes[0].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  # Plot histogram for Test Dataset\n",
        "  bars_test = axes[1].bar(range(10), test_counts, tick_label=range(10), color='seagreen')\n",
        "  axes[1].set_xlabel('Class')\n",
        "  axes[1].set_ylabel('Frequency')\n",
        "  axes[1].set_title('Class Frequency in MNIST Test Dataset')\n",
        "  axes[1].set_xticklabels(range(10), rotation=0)\n",
        "\n",
        "  # Add values on top of each bar for Test Dataset\n",
        "  for bar in bars_test:\n",
        "      height = bar.get_height()\n",
        "      axes[1].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0hi7d3-irJ5z"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  #compute the ratio between each class in the Train + Val dataset vs the highest frequency class\n",
        "  #find the highest frequency\n",
        "  highest_frequency_trainval = max(trainval_counts)\n",
        "  #coumpute the ratio for each class\n",
        "  ratios_trainval = trainval_counts / highest_frequency_trainval\n",
        "  # Display the ratios\n",
        "  for i, ratio in enumerate(ratios_trainval):\n",
        "      print(f'Class {i}: {ratio:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6-Px-_Nr3pG"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  #compute the ratio between each class in the Test dataset vs the highest frequency class\n",
        "  #find the highest frequency\n",
        "  highest_frequency_test = max(test_counts)\n",
        "  #coumpute the ratio for each class\n",
        "  ratios_test = test_counts / highest_frequency_test\n",
        "  # Display the ratios\n",
        "  for i, ratio in enumerate(ratios_test):\n",
        "      print(f'Class {i}: {ratio:.2f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHyS8Kn_sN1W"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # make a plot to compare the two distributions\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(ratios_trainval, label='Train + Val', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_test, label='Test', linestyle='--', marker='o', color = 'seagreen')\n",
        "  plt.xlabel('Class')\n",
        "  plt.ylabel('Ratio')\n",
        "  plt.title('Class ratio in Train+Val vs Test Datasets')\n",
        "  plt.xticks(range(len(ratios_trainval)))\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_trainval):\n",
        "      plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Test dataset\n",
        "  for i, value in enumerate(ratios_test):\n",
        "      plt.text(i, value, f'{value:.2f}', ha='center', va='bottom')\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LnLqEeQjubyV"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # do the ratio vs the total number of samples for each class in Train+Val Dataset\n",
        "  total_samples_trainval = np.sum(trainval_counts)\n",
        "  ratios_trainval_total = trainval_counts / total_samples_trainval\n",
        "  #display the ratios\n",
        "  for i, ratio in enumerate(ratios_trainval_total):\n",
        "      print(f'Class {i}: {ratio:.3f}')\n",
        "\n",
        "  #check print total_samples_trainval\n",
        "  print(f'Total samples in Train+Val Dataset: {total_samples_trainval}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Hde7829uvrV"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # do the ratio vs the total number of samples for each class in Test Dataset\n",
        "  total_samples_test = np.sum(test_counts)\n",
        "  ratios_test_total = test_counts / total_samples_test\n",
        "  #display the ratios\n",
        "  for i, ratio in enumerate(ratios_test_total):\n",
        "      print(f'Class {i}: {ratio:.3f}')\n",
        "\n",
        "  #check print total_samples_test\n",
        "  print(f'Total samples in Test Dataset: {total_samples_test}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yRLugBhOu3nU"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 and do_mnist_data_analysis == 1:\n",
        "  # make a plot to compare ratios_test_total vs ratios_trainval_total\n",
        "  plt.figure(figsize=(10,6))\n",
        "  plt.plot(ratios_trainval_total, label='Train + Val', linestyle='--', marker='o')\n",
        "  plt.plot(ratios_test_total, label='Test', linestyle='--', marker='o', color = 'seagreen')\n",
        "  plt.xlabel('Class')\n",
        "  plt.ylabel('Ratio')\n",
        "  plt.title('Class ratio in Train+Val vs Test Datasets')\n",
        "  plt.xticks(range(len(ratios_trainval_total)))\n",
        "  plt.legend()\n",
        "  plt.grid(True)\n",
        "\n",
        "  # Add values on top of each point for Train + Val dataset\n",
        "  for i, value in enumerate(ratios_trainval_total):\n",
        "    plt.text(i, value, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "  # Add values on top of each point for Test dataset\n",
        "  for i, value in enumerate(ratios_test_total):\n",
        "    plt.text(i, value, f'{value:.3f}', ha='center', va='bottom')\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jN-9DBVSXj01"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZe9aubHVZae"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  imgs_mnist = torch.stack([img for img, _ in trainval_mnist])\n",
        "  mean_mnist = imgs_mnist.mean(dim=(0, 2, 3))\n",
        "  std_mnist = imgs_mnist.std(dim=(0, 2, 3))\n",
        "  print(f\"Mean: {mean_mnist}\")\n",
        "  print(f\"Std: {std_mnist}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6y-2YOuP4O1H"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  transform_mnist = transforms.Compose([\n",
        "          transforms.ToTensor(),                                 #converts PIL images into PyTorch tensor and normalizes from [0,255] to [0.0,1.0]\n",
        "          transforms.Normalize(\n",
        "          mean = mean_mnist,                                     #mean values for MNIST dataset\n",
        "          std = std_mnist                                        #standard deviation values for MNIST dataset\n",
        "          )                                                      #normalization; mean = 0.1307 | std.dev = 0.3081\n",
        "          ])\n",
        "\n",
        "  trainval_mnist = datasets.MNIST('../data', train=True, download=True,  # trainval = train + validation set\n",
        "                        transform=transform_mnist)\n",
        "  test_mnist = datasets.MNIST('../data', train=False, download=True,  #according to documentaton download = True does not download test set if it is already download.\n",
        "                                                                      #[https://pytorch.org/vision/main/generated/torchvision.datasets.MNIST.html]\n",
        "                        transform=transform_mnist)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  val_ratio_mnist = 0.1                                                                   #portion of training set used as validation set [10%]\n",
        "  val_size_mnist = int(val_ratio_mnist*len(trainval_mnist))                               #calculation of validation set dimension\n",
        "  train_mnist, val_mnist = random_split(trainval_mnist, [len(trainval_mnist) - val_size_mnist,\n",
        "                                                      val_size_mnist])                   #divide the training set (split_minst) in training set and validation set\n",
        "\n",
        "  #https://pytorch.org/docs/stable/notes/randomness.html#cuda-convolution-benchmarking\n",
        "  #DataLoader will reseed workers following Randomness in multi-process data loading algorithm.\n",
        "  #Use worker_init_fn() and generator to preserve reproducibility:\n",
        "\n",
        "  num_workers = 0 #default [https://pytorch.org/docs/stable/data.html#data-loading-randomness]\n",
        "  def seed_worker(worker_id):\n",
        "      worker_seed = torch.initial_seed() % 2**32\n",
        "      numpy.random.seed(worker_seed)\n",
        "      random.seed(worker_seed)\n",
        "\n",
        "  g = torch.Generator()\n",
        "  g.manual_seed(0)\n",
        "\n",
        "  train_mnist_loader = data.DataLoader(train_mnist, batch_size = 100, num_workers=num_workers,worker_init_fn=seed_worker, generator=g) #minibatch for training\n",
        "  val_mnist_loader = data.DataLoader(val_mnist, batch_size = 1000,  num_workers=num_workers,worker_init_fn=seed_worker, generator=g)   #minibatch for validation\n",
        "  test_mnist_loader = data.DataLoader(test_mnist, batch_size = 1000,  num_workers=num_workers,worker_init_fn=seed_worker, generator=g) #minibatch for testing\n",
        "\n",
        "  #train_mnist_loader = data.DataLoader(train_mnist, batch_size = 100, shuffle = True)    #minibatch for training\n",
        "  #val_mnist_loader = data.DataLoader(val_mnist, batch_size = 1000, shuffle = True)       #minibatch for validation\n",
        "  #test_mnist_loader = data.DataLoader(test_mnist, batch_size = 1000, shuffle = False)    #minibatch for testing\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ajB6Yvt_mMJ"
      },
      "source": [
        "## CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78O9qHG6hECC"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Load CIFAR-10 dataset\n",
        "  transform = transforms.ToTensor()\n",
        "  trainval_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
        "  test_cifar = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "  # Define the classes in the CIFAR-10 dataset\n",
        "  classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKtXStLWy9y3"
      },
      "source": [
        "### Dataset Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymhF7-5WhcUP"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  # Dataset size\n",
        "  print(f\"Training + Validation Set Size: {len(trainval_cifar)} images\")\n",
        "  print(f\"Test Set Size: {len(test_cifar)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCqRV71lPBO4"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  # check if there are NaNs in the dataset\n",
        "  print(np.isnan(trainval_cifar.data).any())\n",
        "  print(np.isnan(test_cifar.data).any())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SMTY7tmniPCW"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  # Studying resolutions\n",
        "  trainval_resolutions = [img.shape[1:] for img, _ in trainval_cifar]+[img.shape[1:] for img, _ in test_cifar]\n",
        "  test_resolutions = [img.shape[1:] for img, _ in test_cifar]\n",
        "  resolutions = trainval_resolutions + test_resolutions\n",
        "  unique_resolutions = set(resolutions)\n",
        "  print(\"Unique resolutions:\", unique_resolutions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7R58lPgtsSm"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  # Define figure size and grid layout\n",
        "  fig, axes = plt.subplots(nrows=10, ncols=10, figsize=(12, 12))\n",
        "\n",
        "  # Create a dictionary to store 10 images per class\n",
        "  class_images = {cls: [] for cls in range(10)}  # 10 classes in CIFAR-10\n",
        "\n",
        "  # Loop through the dataset to collect 10 images per class\n",
        "  for img, label in test_cifar:\n",
        "      if len(class_images[label]) < 10:  # Check if we have collected 10 images for this class\n",
        "          class_images[label].append(img)\n",
        "\n",
        "      # Stop once we've collected 10 images for each class\n",
        "      if all(len(images) == 10 for images in class_images.values()):\n",
        "          break\n",
        "\n",
        "  # Loop through the axes and plot images for each class\n",
        "  for i, (cls, images) in enumerate(class_images.items()):\n",
        "      # Display the class name once at the top of each column\n",
        "      ax = axes[0, i]  # Top row, each column corresponds to a class\n",
        "      ax.set_title(classes[cls], fontsize=12)  # Set the class name as title\n",
        "      ax.axis('off')  # Hide axis for the title cell\n",
        "\n",
        "      # Loop through the images for this class and plot them in the column\n",
        "      for j, img in enumerate(images):\n",
        "          ax = axes[j, i]  # Set the row for the images (starting from row 1)\n",
        "          npimg = img.numpy()  # Convert to numpy\n",
        "          ax.imshow(np.transpose(npimg, (1, 2, 0)))  # Display image with the correct channel order\n",
        "          ax.axis('off')  # Hide axis for better visualization\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H4U05WFUQcs2"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  all_pixels_trainval = {\"R\": [], \"G\": [], \"B\": []}\n",
        "\n",
        "  for image, label in trainval_cifar:\n",
        "      image = image.numpy() * 255\n",
        "      image = image.astype(int)\n",
        "      all_pixels_trainval[\"R\"].extend(image[0].flatten())\n",
        "      all_pixels_trainval[\"G\"].extend(image[1].flatten())\n",
        "      all_pixels_trainval[\"B\"].extend(image[2].flatten())\n",
        "\n",
        "  fig, axs = plt.subplots(1, 3, figsize=(20,6))\n",
        "  colors = {\"R\": \"red\", \"G\": \"green\", \"B\": \"blue\"}\n",
        "\n",
        "  for i, (channel, color) in enumerate(colors.items()):\n",
        "      _, pixel_counts_trainval = np.unique(np.array(all_pixels_trainval[channel]),\n",
        "                                                              return_counts=True)\n",
        "      axs[i].bar(np.arange(256), pixel_counts_trainval, color=color, width=3)\n",
        "      axs[i].set_xlabel(\"Pixel Values\", fontsize=14, fontweight=\"bold\")\n",
        "      axs[i].set_ylabel(\"Frequency\", fontsize=14, fontweight=\"bold\")\n",
        "      axs[i].set_title(f\"{channel}-channel Pixel Values in Train+Val Set\", fontsize=16, fontweight=\"bold\")\n",
        "      axs[i].grid(True)\n",
        "      axs[i].ticklabel_format(style=\"plain\", axis=\"y\")\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g336OFiHXSFc"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  from collections import defaultdict\n",
        "\n",
        "  # Dizionario per memorizzare i valori medi dei pixel per ogni classe e canale\n",
        "  class_avg_pixel_values = {\"R\": defaultdict(list), \"G\": defaultdict(list), \"B\": defaultdict(list)}\n",
        "\n",
        "  # Itera sul dataset di addestramento\n",
        "  for image, label in trainval_cifar:\n",
        "      image = image.numpy() * 255 # Converti il tensore in array numpy\n",
        "      # Calcola la media dei pixel per ogni canale\n",
        "      class_avg_pixel_values[\"R\"][label].append(image[0].mean())\n",
        "      class_avg_pixel_values[\"G\"][label].append(image[1].mean())\n",
        "      class_avg_pixel_values[\"B\"][label].append(image[2].mean())\n",
        "\n",
        "  # Converti le liste in array numpy\n",
        "  for channel in class_avg_pixel_values:\n",
        "      for class_label in class_avg_pixel_values[channel]:\n",
        "          class_avg_pixel_values[channel][class_label] = np.array(class_avg_pixel_values[channel][class_label])\n",
        "\n",
        "  # Creazione della figura in formato verticale\n",
        "  fig, axs = plt.subplots(10, 3, figsize=(12, 25), sharex=True, sharey=True)\n",
        "  colors = {\"R\": \"red\", \"G\": \"green\", \"B\": \"blue\"}\n",
        "\n",
        "  # Itera su ogni classe e canale per creare gli istogrammi\n",
        "  for class_label in range(10):\n",
        "      for i, (channel, color) in enumerate(colors.items()):\n",
        "          avg_values = class_avg_pixel_values[channel][class_label]\n",
        "          axs[class_label, i].hist(avg_values, bins=50, color=color)\n",
        "          axs[class_label, i].set_title(f'Class {classes[class_label]} - {channel} channel', fontsize=10)\n",
        "          axs[class_label, i].set_xlabel('Avg Pixel Value')\n",
        "          axs[class_label, i].set_ylabel('Frequency')\n",
        "          axs[class_label, i].grid(True)\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZXca8kdtGPr"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1 and do_cifar_data_analysis == 1:\n",
        "  # Function to compute class frequency\n",
        "  def compute_class_frequencies(dataset):\n",
        "      labels = np.array([label for _, label in dataset])  # Extract labels\n",
        "      label_counts = np.zeros(10, dtype=int)  # Array to store class counts\n",
        "      for label in labels:\n",
        "          label_counts[label] += 1  # Count occurrences\n",
        "      return label_counts\n",
        "\n",
        "  # Compute class frequencies for both datasets\n",
        "  trainval_counts = compute_class_frequencies(trainval_cifar)\n",
        "  test_counts = compute_class_frequencies(test_cifar)\n",
        "\n",
        "  # Create a 1-row, 2-column subplot\n",
        "  fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "  # Plot histogram for Train + Validation Dataset\n",
        "  bars_trainval = axes[0].bar(range(10), trainval_counts, tick_label=classes, color='royalblue')\n",
        "  axes[0].set_xlabel('Class')\n",
        "  axes[0].set_ylabel('Frequency')\n",
        "  axes[0].set_title('Class Frequency in CIFAR-10 Training Data')\n",
        "  axes[0].set_xticklabels(classes, rotation=45)\n",
        "\n",
        "  # Add values on top of each bar for Test Dataset\n",
        "  for bar in bars_trainval:\n",
        "      height = bar.get_height()\n",
        "      axes[0].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  # Plot histogram for Test Dataset\n",
        "  bars_test = axes[1].bar(range(10), test_counts, tick_label=classes, color='seagreen')\n",
        "  axes[1].set_xlabel('Class')\n",
        "  axes[1].set_ylabel('Frequency')\n",
        "  axes[1].set_title('Class Frequency in CIFAR-10 Test Data')\n",
        "  axes[1].set_xticklabels(classes, rotation=45)\n",
        "\n",
        "  # Add values on top of each bar for Test Dataset\n",
        "  for bar in bars_test:\n",
        "      height = bar.get_height()\n",
        "      axes[1].text(bar.get_x() + bar.get_width() / 2, height, f'{height}', ha='center', va='bottom')\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qj4VOtPVzBv_"
      },
      "source": [
        "### Data Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZOAT7A1qivNQ"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Compute mean and std of dataset\n",
        "  imgs_cifar = torch.stack([img for img, _ in trainval_cifar])\n",
        "  mean_cifar = imgs_cifar.mean(dim=(0, 2, 3))\n",
        "  std_cifar = imgs_cifar.std(dim=(0, 2, 3))\n",
        "  print(f\"Mean: {mean_cifar}\")\n",
        "  print(f\"Std: {std_cifar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N9Hu4m2ZFUDa"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Define data transformations\n",
        "  transform_cifar = transforms.Compose(\n",
        "      [\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "\n",
        "        # Normalize the tensor using the CIFAR-10 mean and std deviation\n",
        "        transforms.Normalize(\n",
        "          mean = mean_cifar,  # mean values for CIFAR-10 dataset\n",
        "          std = std_cifar     # standard deviation values for CIFAR-10 dataset\n",
        "        )\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  # Load the CIFAR-10 training dataset with the applied transformations\n",
        "  trainval_cifar = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_cifar)\n",
        "\n",
        "  # Load the CIFAR-10 test dataset with the applied transformations\n",
        "  test_cifar = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_cifar)\n",
        "\n",
        "  # Define a validation set ratio (e.g., 10% of the training data)\n",
        "  val_ratio_cifar = 0.1\n",
        "\n",
        "  # Calculate the number of samples in the validation set\n",
        "  val_size_cifar = int(val_ratio_cifar * len(trainval_cifar))\n",
        "\n",
        "  # Split the training data into training and validation sets\n",
        "  train_cifar, val_cifar = data.random_split(trainval_cifar,\n",
        "                              [len(trainval_cifar) - val_size_cifar, val_size_cifar])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ-McPr-vL2S"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Define data transformations for the training and validation sets\n",
        "  augment_cifar = transforms.Compose(\n",
        "      [\n",
        "        # Randomly crop the image to 32x32 and add 4 pixels of padding\n",
        "        transforms.RandomCrop(32, padding = 4),\n",
        "\n",
        "        # Randomly flip the image horizontally for data augmentation\n",
        "        # Data augmentation helps improve generalization by introducing variations in the data\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "\n",
        "        # Convert the image to a PyTorch tensor\n",
        "        transforms.ToTensor(),\n",
        "\n",
        "        # Normalize the tensor using the CIFAR-10 mean and std deviation\n",
        "        transforms.Normalize(\n",
        "          mean = mean_cifar,  # mean values for CIFAR-10 dataset\n",
        "          std = std_cifar     # standard deviation values for CIFAR-10 dataset\n",
        "        )\n",
        "      ]\n",
        "  )\n",
        "\n",
        "  train_cifar.dataset = copy.copy(trainval_cifar)\n",
        "  train_cifar.dataset.transform = augment_cifar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-kJAOBg2pHv"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Dataset size\n",
        "  print(f\"Training Set Size: {len(train_cifar)} images\")\n",
        "  print(f\"Validation Set Size: {len(val_cifar)} images\")\n",
        "  print(f\"Test Set Size: {len(test_cifar)} images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27F1fl6wvgWk"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Create a DataLoader for the training data with batch size of 128 and shuffling enabled\n",
        "  train_cifar_loader = data.DataLoader(train_cifar, batch_size=128, shuffle=True)\n",
        "\n",
        "  # Create a DataLoader for the validation data with batch size of 1024 and shuffling enabled\n",
        "  val_cifar_loader = data.DataLoader(val_cifar, batch_size=1024, shuffle=True)\n",
        "\n",
        "  # Create a DataLoader for the test data with batch size of 1024 and shuffling disabled\n",
        "  test_cifar_loader = data.DataLoader(test_cifar, batch_size=1024, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0F714feEsgX-"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Define figure size and layout (1 row, 10 columns)\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=10, figsize=(12, 4))\n",
        "\n",
        "  # Iterate over the first 10 images from train_cifar\n",
        "  for i, (img, label) in enumerate(train_cifar):\n",
        "      if i == 10:  # Stop after 10 images\n",
        "          break\n",
        "      img = img = img * std_cifar[:, None, None] + mean_cifar[:, None, None]    # Unnormalize the image\n",
        "      axes[i].imshow(img.permute(1, 2, 0))  # Convert (C, H, W) to (H, W, C) for plotting\n",
        "      axes[i].axis(\"off\")  # Hide axis for better visualization\n",
        "\n",
        "  # Adjust layout\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZNqETkceG9Mo"
      },
      "source": [
        "# **Architectures**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OaDEbvZEQAWl"
      },
      "source": [
        "### LeNet-5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F28ClYJ0QNRI"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # See https://github.com/pytorch/examples/blob/main/mnist/main.py\n",
        "\n",
        "  class LeNet5(nn.Module):\n",
        "\n",
        "      def __init__(self):                       #initialization for the architecture LeNet5\n",
        "          super().__init__()\n",
        "          self.conv1 = nn.Conv2d(1, 32, 3, 1)   #First convolutional layer with 1 input channel, 32 output channels, 3x3 kernel size, and stride of 1.\n",
        "          self.conv2 = nn.Conv2d(32, 64, 3, 1)  #Second convolutional layer with 32 input channels, 64 output channels, 3x3 kernel size, and stride of 1.\n",
        "          self.dropout1 = nn.Dropout(0.25)      #First dropout layer with a dropout probability of 25% to reduce overfitting.\n",
        "          self.dropout2 = nn.Dropout(0.5)       #Second dropout layer with a dropout probability of 50%.\n",
        "          self.fc1 = nn.Linear(9216, 128)       #First fully connected layer with 9216 input neurons and 128 output neurons.\n",
        "          self.fc2 = nn.Linear(128, 10)         #Second fully connected layer with 128 input neurons and 10 output neurons (one for each class).\n",
        "\n",
        "      def forward(self, x):                     #Defines the forward pass of the data through the network.\n",
        "          x = self.conv1(x)                     #Applies the first convolutional layer.\n",
        "          x = F.relu(x)                         #Applies ReLU.\n",
        "          x = self.conv2(x)\n",
        "          x = F.relu(x)\n",
        "          x = F.max_pool2d(x, 2)                #Applies max pooling with a 2x2 window, reducing the spatial dimensions.\n",
        "          x = self.dropout1(x)                  #Applies the first dropout layer.\n",
        "          x = torch.flatten(x, 1)               #Flattens the tensor while retaining the batch dimension. from multidimension to 2D tensor\n",
        "          x = self.fc1(x)\n",
        "          x = F.relu(x)\n",
        "          x = self.dropout2(x)\n",
        "          x = self.fc2(x)\n",
        "          return F.log_softmax(x, dim=1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZOh5eJBQPXs"
      },
      "source": [
        "### ResNet-18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXi0B-btJ4ik"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  class BasicBlock(nn.Module):\n",
        "\n",
        "      def __init__(self, in_channels, out_channels, stride=1):\n",
        "          super().__init__()\n",
        "\n",
        "          self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)          #1st convolutional layer\n",
        "          self.bn1 = nn.BatchNorm2d(out_channels)                                                             #1st batch normalization (bn)\n",
        "          self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)  #2nd convolutional layer\n",
        "          self.bn2 = nn.BatchNorm2d(out_channels)                                                             #2nd batch normalization (bn)\n",
        "\n",
        "          #define shortcut connection\n",
        "          self.shortcut = nn.Sequential()                                                                    #defines an empty sequential container for the shortcut connection\n",
        "          if stride != 1 or in_channels != out_channels:\n",
        "              self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),             #from paper https://doi.org/10.48550/arXiv.1512.03385 pag4+5\n",
        "                nn.BatchNorm2d(out_channels)\n",
        "                    )\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          out = self.conv1(x)\n",
        "          out = self.bn1(out)\n",
        "          out = F.relu(out)\n",
        "          out = self.conv2(out)\n",
        "          out = self.bn2(out)\n",
        "          out += self.shortcut(x)\n",
        "          out = F.relu(out)\n",
        "          return out\n",
        "\n",
        "\n",
        "\n",
        "  #ref. doc [(https://pytorch.org/vision/main/models/generated/torchvision.models.resnet18.html)]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DJDTtkBlV0V"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  class ResNet18(nn.Module):\n",
        "\n",
        "      def __init__(self):\n",
        "          super().__init__()\n",
        "          self.in_channels = 64\n",
        "          self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, bias=False)\n",
        "          self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "          self.layer1 = self._make_layer(BasicBlock, 64,  2, 1)\n",
        "          self.layer2 = self._make_layer(BasicBlock, 128, 2, 2)\n",
        "          self.layer3 = self._make_layer(BasicBlock, 256, 2, 2)\n",
        "          self.layer4 = self._make_layer(BasicBlock, 512, 2, 2)\n",
        "\n",
        "          self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
        "          self.fc = nn.Linear(512, 10)\n",
        "\n",
        "\n",
        "      def _make_layer(self, block, out_channels, num_blocks, stride):\n",
        "          strides = [stride] + [1] * (num_blocks - 1)\n",
        "          layers = []\n",
        "          for stride in strides:\n",
        "              layers.append(block(self.in_channels, out_channels, stride))\n",
        "              self.in_channels = out_channels\n",
        "          return nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "      def forward(self, x):\n",
        "          out = self.conv1(x)\n",
        "          out = self.bn1(out)\n",
        "          out = F.relu(out)\n",
        "\n",
        "          out = self.layer1(out)\n",
        "          out = self.layer2(out)\n",
        "          out = self.layer3(out)\n",
        "          out = self.layer4(out)\n",
        "\n",
        "          out = self.avgpool(out)\n",
        "          out = torch.flatten(out,1)\n",
        "          out = self.fc(out)\n",
        "          return F.log_softmax(out, dim=1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M0i75adDAAEJ"
      },
      "source": [
        "# **Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqX-vdvDF4cF"
      },
      "source": [
        "### Training and Test Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cnKPHGPEZHaB"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  class AverageMeter:\n",
        "      \"\"\"\n",
        "      Keeps track of the average, sum, and count of a given metric.\n",
        "      Useful for monitoring loss and accuracy during training and evaluation.\n",
        "      \"\"\"\n",
        "\n",
        "      def __init__(self, name: str, fmt: str = \":f\") -> None:\n",
        "          \"\"\"\n",
        "          Initializes the meter.\n",
        "\n",
        "          Parameters:\n",
        "              name (str): Name of the metric being tracked.\n",
        "              fmt (str, optional): Format string for displaying values (default: ':f').\n",
        "          \"\"\"\n",
        "          self.name = name\n",
        "          self.fmt = fmt\n",
        "          self.reset()\n",
        "\n",
        "      def reset(self) -> None:\n",
        "          \"\"\"Resets all tracked values to zero.\"\"\"\n",
        "          self.val = 0.0\n",
        "          self.avg = 0.0\n",
        "          self.sum = 0.0\n",
        "          self.count = 0\n",
        "\n",
        "      def update(self, val: float, n: int = 1) -> None:\n",
        "          \"\"\"\n",
        "          Updates the meter with a new value.\n",
        "\n",
        "          Parameters:\n",
        "              val (float): New value to add.\n",
        "              n (int, optional): Number of occurrences (default: 1).\n",
        "          \"\"\"\n",
        "          self.val = val\n",
        "          self.sum += val * n\n",
        "          self.count += n\n",
        "          self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNbIAHv0QVw6"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  #This is the train function\n",
        "  def train(model: nn.Module, train_loader: data.DataLoader, optimizer: torch.optim.Optimizer,\n",
        "            loss: nn.Module, spars: float = 0, epoch: int = 1, device: str = \"cpu\") -> tuple[float, float]:\n",
        "      \"\"\"\n",
        "      Trains the model for one epoch.\n",
        "\n",
        "      Parameters:\n",
        "          model (nn.Module): The PyTorch model to train.\n",
        "          train_loader (DataLoader): DataLoader providing training batches.\n",
        "          optimizer (torch.optim.Optimizer): Optimizer used for updating model parameters.\n",
        "          loss (nn.Module): Loss function used for training.\n",
        "          spars (float, optional): Sparsity level of the model (default: 0).\n",
        "          epoch (int, optional): Current epoch number (default: 1).\n",
        "          device (str, optional): Device to run training on (\"cpu\" or \"cuda\", default: \"cpu\").\n",
        "\n",
        "      Returns:\n",
        "          tuple[float, float]: Final loss and classification error of the epoch.\n",
        "      \"\"\"\n",
        "\n",
        "      model.train()  # Set the model to training mode\n",
        "\n",
        "      # Initialize tqdm progress bar for visualization\n",
        "      progress_bar = tqdm(train_loader, total=len(train_loader),\n",
        "                          desc=f\"TRAIN | Epoch {epoch} | Sparsity: {spars}\")\n",
        "\n",
        "      mean_train_loss = AverageMeter(\"train_loss\")\n",
        "      mean_train_error = AverageMeter(\"train_error\")\n",
        "\n",
        "      for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "          # Move data and target to the specified device\n",
        "          data, target = data.to(device), target.to(device)\n",
        "\n",
        "          # Forward pass\n",
        "          output = model(data)\n",
        "          this_loss = loss(output, target)  # Compute loss\n",
        "\n",
        "          # Compute classification error percentage\n",
        "          this_error = torch.mean((output.argmax(dim=1) != target) * 100.0)\n",
        "\n",
        "          # Update metrics\n",
        "          mean_train_loss.update(this_loss.item())\n",
        "          mean_train_error.update(this_error.item())\n",
        "\n",
        "          # Backpropagation and optimization step\n",
        "          optimizer.zero_grad()\n",
        "          this_loss.backward()\n",
        "          optimizer.step()\n",
        "\n",
        "          # Update progress bar with loss and error\n",
        "          progress_bar.set_postfix(loss=mean_train_loss.avg, error=mean_train_error.avg)\n",
        "\n",
        "      return mean_train_loss.avg, mean_train_error.avg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSgNH2_zQqEG"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "\n",
        "  def valid(model: nn.Module, val_loader: data.DataLoader, loss: nn.Module,\n",
        "            spars: float = 0, epoch: int = 1, device: str = \"cpu\") -> tuple[float, float]:\n",
        "      \"\"\"\n",
        "      Runs validation on the given model.\n",
        "\n",
        "      Parameters:\n",
        "          model (nn.Module): The PyTorch model to validate.\n",
        "          val_loader (DataLoader): DataLoader for validation data.\n",
        "          loss (nn.Module): Loss function used for evaluation.\n",
        "          spars (float, optional): Sparsity level of the model (default: 0).\n",
        "          epoch (int, optional): Current epoch number (default: 1).\n",
        "          device (str, optional): Device to run validation on (\"cpu\" or \"cuda\", default: \"cpu\").\n",
        "\n",
        "      Returns:\n",
        "          tuple[float, float]: Final average loss and classification error.\n",
        "      \"\"\"\n",
        "\n",
        "      progress_bar = tqdm(val_loader, total=len(val_loader),\n",
        "                          desc=f\"VALIDATION | Epoch {epoch} | Sparsity: {spars}\")\n",
        "\n",
        "      mean_val_loss = AverageMeter(\"val_loss\")\n",
        "      mean_val_error = AverageMeter(\"val_error\")\n",
        "\n",
        "      model.eval()  # Set model to evaluation mode\n",
        "      with torch.no_grad():  # Disable gradient calculation for efficiency\n",
        "          for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "              data, target = data.to(device), target.to(device)\n",
        "\n",
        "              # Forward pass\n",
        "              output = model(data)\n",
        "              this_loss = loss(output, target)\n",
        "\n",
        "              # Compute classification error\n",
        "              this_error = torch.mean((output.argmax(dim=1) != target) * 100.0)\n",
        "\n",
        "              # Update metrics\n",
        "              mean_val_loss.update(this_loss.item())\n",
        "              mean_val_error.update(this_error.item())\n",
        "\n",
        "              # Update progress bar\n",
        "              progress_bar.set_postfix(loss=mean_val_loss.avg, error=mean_val_error.avg)\n",
        "\n",
        "      return mean_val_loss.avg, mean_val_error.avg\n",
        "\n",
        "\n",
        "\n",
        "  def test(model: nn.Module, test_loader: data.DataLoader, loss: nn.Module,\n",
        "          spars: float = 0, device: str = \"cpu\") -> tuple[float, float]:\n",
        "      \"\"\"\n",
        "      Runs testing on the given model.\n",
        "\n",
        "      Parameters:\n",
        "          model (nn.Module): The PyTorch model to test.\n",
        "          test_loader (DataLoader): DataLoader for test data.\n",
        "          loss (nn.Module): Loss function used for evaluation.\n",
        "          spars (float, optional): Sparsity level of the model (default: 0).\n",
        "          device (str, optional): Device to run testing on (\"cpu\" or \"cuda\", default: \"cpu\").\n",
        "\n",
        "      Returns:\n",
        "          tuple[float, float]: Final average loss and classification error.\n",
        "      \"\"\"\n",
        "\n",
        "      progress_bar = tqdm(test_loader, total=len(test_loader),\n",
        "                          desc=f\"TEST | Sparsity: {spars}\")\n",
        "\n",
        "      mean_test_loss = AverageMeter(\"test_loss\")\n",
        "      mean_test_error = AverageMeter(\"test_error\")\n",
        "\n",
        "      model.eval()  # Set model to evaluation mode\n",
        "      with torch.no_grad():  # Disable gradient calculation for efficiency\n",
        "          for batch_idx, (data, target) in enumerate(progress_bar):\n",
        "              data, target = data.to(device), target.to(device)\n",
        "\n",
        "              # Forward pass\n",
        "              output = model(data)\n",
        "              this_loss = loss(output, target)\n",
        "\n",
        "              # Compute classification error\n",
        "              this_error = torch.mean((output.argmax(dim=1) != target) * 100.0)\n",
        "\n",
        "              # Update metrics\n",
        "              mean_test_loss.update(this_loss.item())\n",
        "              mean_test_error.update(this_error.item())\n",
        "\n",
        "              # Update progress bar\n",
        "              progress_bar.set_postfix(loss=mean_test_loss.avg, error=mean_test_error.avg)\n",
        "\n",
        "      return mean_test_loss.avg, mean_test_error.avg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsyrDtkgFxnY"
      },
      "source": [
        "### Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qI9hbyFlR_b"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  from typing import Iterable, List  # Import Iterable and List type hints\n",
        "\n",
        "\n",
        "  def snip_forward_conv2d(self: nn.Conv2d, x: torch.Tensor) -> torch.Tensor:\n",
        "      \"\"\"Custom forward for Conv2d layers using a weight mask.\"\"\"\n",
        "      # Apply padding manually before convolution to match original behavior\n",
        "      padding = self.padding  # Get original padding values\n",
        "\n",
        "      # Pad the input tensor\n",
        "      x = F.pad(x, (padding[1], padding[1], padding[0], padding[0]))\n",
        "\n",
        "      # Apply convolution with mask This\n",
        "      return F.conv2d(x, self.weight*self.weight_mask, self.bias, self.stride)\n",
        "\n",
        "\n",
        "  def snip_forward_linear(self: nn.Linear, x: torch.Tensor) -> torch.Tensor:\n",
        "      \"\"\"Custom forward for Linear layers using a weight mask.\"\"\"\n",
        "      return F.linear(x, self.weight * self.weight_mask, self.bias)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def SNIP(model: nn.Module, spars: float, train_loader: data.DataLoader,\n",
        "          loss: nn.Module, device: str = \"cpu\") -> List[torch.Tensor]:\n",
        "      \"\"\"\n",
        "      Implements the SNIP pruning algorithm to determine which parameters\n",
        "      to keep for a given sparsity level.\n",
        "\n",
        "      This function creates a copy of the model, attaches a mask to each\n",
        "      prunable layer (Conv2d and Linear), overrides their forward passes,\n",
        "      and then computes the gradient-based importance scores.\n",
        "\n",
        "      Parameters:\n",
        "          model (nn.Module): The model to be pruned.\n",
        "          sparsity (float): Fraction of parameters to prune (0 <= sparsity < 1).\n",
        "          train_loader: A DataLoader from which the first mini-batch is taken.\n",
        "          loss_fn: Loss function to compute the loss.\n",
        "          device (str): Device to run the model on (\"cpu\" or \"cuda\").\n",
        "\n",
        "      Returns:\n",
        "          List[torch.Tensor]: A list of binary masks for each prunable layer.\n",
        "      \"\"\"\n",
        "      # Fetch one mini-batch and send to device.\n",
        "      data, target = next(iter(train_loader))\n",
        "      data, target = data.to(device), target.to(device)\n",
        "\n",
        "      # Create a copy of the model and move it to the specified device.\n",
        "      snip_model = copy.deepcopy(model).to(device)\n",
        "\n",
        "      # Attach a weight mask to each prunable layer and override its forward method.\n",
        "      for layer in snip_model.modules():\n",
        "          if isinstance(layer, (nn.Conv2d, nn.Linear)):\n",
        "              # Initialize a mask of ones (same shape as weights).\n",
        "              layer.weight_mask = nn.Parameter(torch.ones_like(layer.weight))\n",
        "              # Freeze the original weights so they are not updated.\n",
        "              layer.weight.requires_grad = False\n",
        "\n",
        "              # Override the forward pass with our custom SNIP forward.\n",
        "              if isinstance(layer, nn.Conv2d):\n",
        "                  layer.forward = types.MethodType(snip_forward_conv2d, layer)\n",
        "              elif isinstance(layer, nn.Linear):\n",
        "                  layer.forward = types.MethodType(snip_forward_linear, layer)\n",
        "\n",
        "      # Forward pass and compute gradients.\n",
        "      snip_model.zero_grad()\n",
        "      output = snip_model(data)\n",
        "      loss_value = loss(output, target)\n",
        "      loss_value.backward()\n",
        "\n",
        "      # Collect the absolute gradients of the weight masks.\n",
        "      grads_abs = [\n",
        "          torch.abs(layer.weight_mask.grad)\n",
        "          for layer in snip_model.modules()\n",
        "          if isinstance(layer, (nn.Conv2d, nn.Linear))\n",
        "          ]\n",
        "\n",
        "      # Concatenate all gradients into a single vector and normalize.\n",
        "      all_scores = torch.cat([g.flatten() for g in grads_abs])\n",
        "      total_score = torch.sum(all_scores)\n",
        "      all_scores_normalized = all_scores / total_score\n",
        "\n",
        "      # Determine the threshold score to keep (1 - sparsity) fraction of parameters.\n",
        "      num_params_to_keep = int(len(all_scores_normalized) * (1 - spars))\n",
        "      threshold_scores, _ = torch.topk(all_scores_normalized, num_params_to_keep, sorted=True)\n",
        "      acceptable_score = threshold_scores[-1]\n",
        "\n",
        "      # Create binary masks.\n",
        "      keep_masks = [\n",
        "          ((g / total_score) >= acceptable_score).float()\n",
        "          for g in grads_abs\n",
        "          ]\n",
        "\n",
        "      # Optionally print the total number of parameters kept.\n",
        "      total_kept = sum(mask.sum().item() for mask in keep_masks)\n",
        "      print(f\"Sparsity: {spars}, Total weights kept: {int(total_kept)}\")\n",
        "\n",
        "      return keep_masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "adIW7ObvHsUg"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  def apply_prune_mask(model: nn.Module, keep_masks: Iterable[torch.Tensor]) -> None:\n",
        "      \"\"\"\n",
        "      Applies pruning masks to the model's prunable layers (Conv2d and Linear).\n",
        "      For each such layer, the weights corresponding to zeros in the keep mask are\n",
        "      set to zero, and a hook is registered to ensure gradients for pruned weights\n",
        "      remain zero during backpropagation.\n",
        "\n",
        "      Parameters:\n",
        "          model (nn.Module): The PyTorch model.\n",
        "          keep_masks (iterable of torch.Tensor): One mask per prunable layer.\n",
        "      \"\"\"\n",
        "      # Filter out the layers we want to prune (Conv2d and Linear)\n",
        "      prunable_layers = [\n",
        "          layer for layer in model.modules()\n",
        "          if isinstance(layer, (nn.Conv2d, nn.Linear))\n",
        "      ]\n",
        "\n",
        "      for layer, keep_mask in zip(prunable_layers, keep_masks):\n",
        "          if layer.weight.shape != keep_mask.shape:\n",
        "              raise ValueError(\n",
        "                  f\"Shape mismatch: {layer.weight.shape} vs {keep_mask.shape}\"\n",
        "              )\n",
        "\n",
        "          # Zero-out the pruned weights using a no_grad context\n",
        "          with torch.no_grad():\n",
        "              layer.weight[keep_mask == 0] = 0.\n",
        "\n",
        "          # Register a hook to maintain zero gradients for pruned weights.\n",
        "          # Using a lambda with a default argument ensures early binding.\n",
        "          layer.weight.register_hook(lambda grad, mask=keep_mask: grad * mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LA44DDBQ4Uh8"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  def plot_conv_filters(tensor, n_rows, RGB=False, title=\"Filters\"):\n",
        "      tensor = tensor.cpu().detach().numpy()\n",
        "      num_filters = tensor.shape[0]  # Number of output channels\n",
        "      if RGB is False:\n",
        "        # Calculate number of columns needed\n",
        "        n_cols = num_filters // n_rows\n",
        "        fig, axes = plt.subplots(n_rows, n_cols, figsize=(n_cols, n_rows))\n",
        "        axes = np.array(axes).reshape(n_rows, n_cols)  # Ensure correct shape\n",
        "        for i in range(n_rows * n_cols):\n",
        "          row, col = divmod(i, n_cols)\n",
        "          if i < num_filters:\n",
        "            binary_mask = (tensor[i, 0] != 0).astype(float)  # Convert to binary\n",
        "            axes[row, col].imshow(binary_mask, vmin=0, vmax=1)  # Fix scaling\n",
        "            axes[row, col].axis(\"off\")\n",
        "      if RGB is True:\n",
        "        cmaps = [\"Reds\", \"Greens\", \"Blues\"]\n",
        "        n_cols = num_filters // n_rows\n",
        "        fig, axes = plt.subplots(n_rows*3, n_cols, figsize=(n_cols, n_rows*3))\n",
        "        axes = np.array(axes).reshape(n_rows*3, n_cols)  # Ensure correct shape\n",
        "        for channel in range(tensor.shape[1]):\n",
        "          for i in range(n_rows * n_cols):\n",
        "            row, col = divmod(i, n_cols)\n",
        "            if i < num_filters:\n",
        "              binary_mask = (tensor[i, channel] != 0).astype(float)  # Convert to binary\n",
        "              axes[row + n_rows*channel, col].imshow(binary_mask, cmap=cmaps[channel], vmin=0, vmax=1)  # Fix scaling\n",
        "              axes[row + n_rows*channel, col].axis(\"off\")\n",
        "\n",
        "      plt.suptitle(title, fontsize=12)  # Increase title font size\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-Ld2PvX4YY8"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1 or run_ResNet_cifar == 1:\n",
        "  def plot_linear_weights(tensor, title=\"Linear Weights\", manual_figsize=(14, 2)):\n",
        "      tensor = tensor.cpu().detach().numpy()  # Convert tensor to numpy\n",
        "      out_features, in_features = tensor.shape  # (output neurons, input neurons)\n",
        "\n",
        "      fig, ax = plt.subplots(figsize=manual_figsize)\n",
        "      binary_mask = (tensor != 0).astype(float)  # Convert to binary mask\n",
        "\n",
        "      # Use a colormap for a smoother look\n",
        "      ax.imshow(binary_mask, vmin=0, vmax=1, aspect='auto')  # \"coolwarm\" colormap\n",
        "      ax.axis(\"off\")  # Hide the axis\n",
        "\n",
        "      # Customize the title\n",
        "      plt.suptitle(title, fontsize=8, ha='center')  # Bold, centered, and colored title\n",
        "\n",
        "      # Adding a subtle grid for structure (optional)\n",
        "      ax.grid(False)  # You can remove or adjust grid if you prefer\n",
        "\n",
        "      # Tighten the layout and show the plot\n",
        "      plt.tight_layout()\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwzSXX8RRZKw"
      },
      "source": [
        "# **MAIN with MNIST**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbkVRW9vScGH"
      },
      "source": [
        "### Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L7gIJHRndzW"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Initialize the LeNet-5 model and move it to the selected device (CPU/GPU)\n",
        "  lenet = LeNet5().to(device)\n",
        "\n",
        "  # Define different sparsity levels for MNIST dataset experiments\n",
        "  # Sparsities_mnist = [0, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 0.995, 0.999]\n",
        "  # Use negative log-likelihood loss\n",
        "  loss = F.nll_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JS0OD04WPDMA"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Dictionary to store pruned versions of LeNet-5 for different sparsity levels\n",
        "  snipped_lenets = {}\n",
        "\n",
        "  total_weights_lenet = sum(p.numel() for name, p in lenet.named_parameters() if \"weight\" in name)\n",
        "  print(f\"Total weights: {total_weights_lenet}\")\n",
        "\n",
        "  # Iterate through the defined sparsity levels\n",
        "  for spar in sparsities_mnist:\n",
        "\n",
        "      # Create a deep copy of the original LeNet-5 model to apply pruning without modifying the original\n",
        "      lenet_copy = copy.deepcopy(lenet)\n",
        "\n",
        "      if spar == 0:\n",
        "        # Store the pruned model in the dictionary, indexed by its corresponding sparsity level\n",
        "        snipped_lenets[spar] = lenet_copy\n",
        "        continue\n",
        "\n",
        "      # Compute the pruning mask using SNIP, which determines which connections to keep\n",
        "      keep_masks = SNIP(lenet, spar, train_mnist_loader, loss, device)\n",
        "\n",
        "      # Apply the computed mask to prune the copied model\n",
        "      apply_prune_mask(lenet_copy, keep_masks)\n",
        "\n",
        "      # Store the pruned model in the dictionary, indexed by its corresponding sparsity level\n",
        "      snipped_lenets[spar] = lenet_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dvsq6R6_DZyo"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        " for spar, model in snipped_lenets.items():\n",
        "      plot_conv_filters(model.conv1.weight, n_rows=1, title=f\"Pruned Filters (conv1) with sparsity={spar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKioXVoQMHnL"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  for spar, model in snipped_lenets.items():\n",
        "      plot_linear_weights(model.fc1.weight, title=f\"Pruned Parameters (fc1) with sparsity={spar}\", manual_figsize=(14, 2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oDms7RUsPXgI"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  for spar, model in snipped_lenets.items():\n",
        "      plot_linear_weights(model.fc2.weight, title=f\"Pruned Parameters (fc2) with sparsity={spar}\", manual_figsize=(8, 1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eP88u9VySftn"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu7yQGYSuq2T"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Dictionaries to store training and validation metrics for different sparsity levels\n",
        "  train_losses_mnist = {}  # Training loss per sparsity level\n",
        "  train_errors_mnist = {}  # Training error per sparsity level\n",
        "  val_losses_mnist = {}    # Validation loss per sparsity level\n",
        "  val_errors_mnist = {}    # Validation error per sparsity level\n",
        "\n",
        "  # Iterate over pruned models at different sparsity levels\n",
        "  for spar, snipped_lenet in snipped_lenets.items():\n",
        "      # Initialize lists to store loss and error per epoch\n",
        "      train_losses_mnist[spar] = []\n",
        "      train_errors_mnist[spar] = []\n",
        "      val_losses_mnist[spar] = []\n",
        "      val_errors_mnist[spar] = []\n",
        "\n",
        "      # Initialize the optimizer for the current pruned model\n",
        "      optimizer = optim.SGD(snipped_lenet.parameters(), lr=lr_mnist)\n",
        "\n",
        "      # Train and validate the model for the defined number of epochs\n",
        "      for epoch in range(1, epochs_mnist + 1):\n",
        "          # Perform training for the current epoch and store the loss and error in lists\n",
        "          train_loss, train_error = train(\n",
        "              snipped_lenet, train_mnist_loader, optimizer, loss, spar, epoch, device\n",
        "          )\n",
        "          train_losses_mnist[spar].append(train_loss)\n",
        "          train_errors_mnist[spar].append(train_error)\n",
        "\n",
        "          # Perform validation for the current epoch and store the loss and error in lists\n",
        "          val_loss, val_error = valid(\n",
        "              snipped_lenet, val_mnist_loader, loss, spar, epoch, device\n",
        "          )\n",
        "          val_losses_mnist[spar].append(val_loss)\n",
        "          val_errors_mnist[spar].append(val_error)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VE8r3yPQoRKF"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Loop through sparsities to plot the graphs for each sparsity value\n",
        "  for sparsity in sparsities_mnist:\n",
        "      epochs = range(1, epochs_mnist + 1)\n",
        "\n",
        "      plt.figure(figsize=(12, 5))\n",
        "\n",
        "      # Plot training and validation loss\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(epochs, train_losses_mnist[sparsity], label=\"Train Loss\", color='tab:blue',\n",
        "              linestyle='dashed', linewidth=2, marker='o', markersize=6)\n",
        "      plt.plot(epochs, val_losses_mnist[sparsity], label=\"Validation Loss\", color='tab:orange',\n",
        "              linestyle='dashed', linewidth=2, marker='s', markersize=6)\n",
        "      plt.xlabel(\"Epochs\", fontsize=12)\n",
        "      plt.ylabel(\"Loss\", fontsize=12)\n",
        "      #plt.xticks(range(1, epochs_mnist + 1, 7), fontsize=10)\n",
        "      plt.title(f\"Loss vs Epochs (Sparsity: {sparsity})\", fontsize=14)\n",
        "      plt.legend(loc='upper right', fontsize=10)\n",
        "      plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "      # Plot training and validation error\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(epochs, train_errors_mnist[sparsity], label=\"Train Error\", color='tab:blue',\n",
        "              linestyle='dashed', linewidth=2, marker='o', markersize=6)\n",
        "      plt.plot(epochs, val_errors_mnist[sparsity], label=\"Validation Error\", color='tab:orange',\n",
        "              linestyle='dashed', linewidth=2, marker='s', markersize=6)\n",
        "      plt.xlabel(\"Epochs\", fontsize=12)\n",
        "      plt.ylabel(\"Error\", fontsize=12)\n",
        "      #plt.xticks(range(1, epochs_mnist + 1, 7), fontsize=10)\n",
        "      plt.title(f\"Error vs Epochs (Sparsity: {sparsity})\", fontsize=14)\n",
        "      plt.legend(loc='upper right', fontsize=10)\n",
        "      plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "      print(train_errors_mnist)\n",
        "      print()\n",
        "      print(val_errors_mnist)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "errors_train_mnist\n",
        "0: 1.35,\n",
        "0.25: 1.3962962962962964,\n",
        "0.5: 1.5777777777777777,\n",
        "0.75: 2.011111111111111,\n",
        " 0.9: 3.4185185185185185,\n",
        "  0.95: 5.174074074074074,\n",
        "   0.99: 10.924074074074074,\n",
        "    0.995: 16.44814814814815,\n",
        "    0.999: 81.20925925925926"
      ],
      "metadata": {
        "id": "LIz5QzWCZOgG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tzof-Hqo1TfJ"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  for spar, snipped_lenet in snipped_lenets.items():\n",
        "      torch.save(snipped_lenet, f'snipped_lenet_{spar}.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uNEQic0lZ0yK"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a5mNl62yZ4_s"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Dictionaries to store test losses and errors for different sparsity levels\n",
        "  test_losses_mnist = {}  # Test loss per sparsity level\n",
        "  test_errors_mnist = {}  # Test error per sparsity level\n",
        "\n",
        "  # Iterate over the pruned models and evaluate them on the test set\n",
        "  for spar, snipped_lenet in snipped_lenets.items():\n",
        "      # Evaluate the model on the test set and store the results\n",
        "      test_losses_mnist[spar], test_errors_mnist[spar] = test(\n",
        "          snipped_lenet, test_mnist_loader, loss, spar, device\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eAicVLYfs7kJ"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Define figure size and grid layout\n",
        "  #fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(8, 8))\n",
        "  fig, axes = plt.subplots(nrows=1, ncols=len(sparsities_mnist), figsize=(25, 25))\n",
        "  # Loop through the grid and plot images with predictions\n",
        "  # In the case of only 1 row/col, axes is not an ndarray but a single Axes object.\n",
        "  # Wrap it in a list to make it iterable, or change subplots(nrows=1...) to subplots(nrows=x...) where x > 1\n",
        "  for i, ax in enumerate(axes if len(sparsities_mnist) > 1 else [axes]):\n",
        "      sample_idx = torch.randint(len(test_mnist), size=(1,)).item()  # Randomly select an image index\n",
        "\n",
        "      img, label = test_mnist[sample_idx]  # Retrieve image and label\n",
        "\n",
        "      # Get model prediction\n",
        "      pred_label = snipped_lenets[sparsities_mnist[i]](img.unsqueeze(0).to(device)).argmax(dim=1).item()\n",
        "\n",
        "      # Display the image\n",
        "      ax.imshow(img.squeeze(), cmap=\"gray\")\n",
        "      ax.set_title(f\"Spar:{sparsities_mnist[i]} Class:{label} Pred:{pred_label}\")\n",
        "      ax.axis(\"off\")  # Hide axis for a cleaner look\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot specific ID image in the test_mnist\n",
        "if run_LeNet_mnist == 1:\n",
        "    # Create a subset of test_mnist with 1000 images\n",
        "    subset_indices = torch.randint(len(test_mnist), size=(1000,))\n",
        "    subset_test_mnist = torch.utils.data.Subset(test_mnist, subset_indices)\n",
        "\n",
        "    # Create a figure and axes for plotting\n",
        "    fig, axes = plt.subplots(nrows=1, ncols=len(sparsities_mnist), figsize=(25, 5))\n",
        "\n",
        "    # Loop through the sparsities and plot predictions for each model\n",
        "    for i, spar in enumerate(sparsities_mnist):\n",
        "        image_index_in_original = 710\n",
        "\n",
        "        # Get the image and label from the original test_mnist dataset\n",
        "        img, label = test_mnist[image_index_in_original]\n",
        "\n",
        "        # Get the actual image ID\n",
        "        image_id = test_mnist.targets[image_index_in_original].item()\n",
        "\n",
        "        # Get model prediction\n",
        "        pred_label = snipped_lenets[spar](img.unsqueeze(0).to(device)).argmax(dim=1).item()\n",
        "\n",
        "        # Display the image on the current subplot\n",
        "        axes[i].imshow(img.squeeze(), cmap=\"gray\")\n",
        "        axes[i].set_title(f\"Spar: {spar}, Class: {label}, Pred: {pred_label}\")\n",
        "        axes[i].axis(\"off\")\n",
        "\n",
        "    # Adjust layout and display the plot\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Yvj0sH0hs-V-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UBoeRwkQvXNd"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Create a figure with 3 subplots in a single row\n",
        "  fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "  last_train_errors_mnist = {}\n",
        "  last_val_errors_mnist = {}\n",
        "\n",
        "  for spar in sparsities_mnist:\n",
        "      last_train_errors_mnist[spar] = train_errors_mnist[spar][-1]\n",
        "      last_val_errors_mnist[spar] = val_errors_mnist[spar][-1]\n",
        "\n",
        "  # Define lists for errors, titles, and labels to iterate efficiently\n",
        "  errors = [last_train_errors_mnist, last_val_errors_mnist, test_errors_mnist]\n",
        "  titles = [\"Training Error\", \"Validation Error\", \"Test Error\"]\n",
        "\n",
        "  # Loop through the three error datasets to plot them\n",
        "  for i, (error, title) in enumerate(zip(errors, titles)):\n",
        "      # Set color palette for lines and scatter points\n",
        "      line_color = 'tab:blue' if i == 0 else 'tab:orange' if i == 1 else 'tab:green'\n",
        "      scatter_color = line_color\n",
        "\n",
        "      # Plot sparsity vs. error (line)\n",
        "      #axs[i].plot(range(len(error.keys())), error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "      axs[i].plot(sparsities_mnist, error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "\n",
        "      # Scatter plot for better visibility\n",
        "      #axs[i].scatter(range(len(error.keys())), error.values(), color=scatter_color, s=80, zorder=5)\n",
        "      axs[i].scatter(sparsities_mnist, error.values(), color=scatter_color, s=80, zorder=5)\n",
        "\n",
        "      # Set y-axis limits for consistency\n",
        "      axs[i].set_ylim(0, 100)\n",
        "\n",
        "\n",
        "      # Add labels and title\n",
        "      axs[i].set_xlabel(\"Sparsity\", fontsize=12)\n",
        "      axs[i].set_ylabel(\"Error\", fontsize=12)\n",
        "      axs[i].set_title(title, fontsize=14)\n",
        "\n",
        "\n",
        "      # Add grid for better readability\n",
        "      axs[i].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "\n",
        "      # Add legend with better positioning\n",
        "      axs[i].legend(loc='upper left', fontsize=10)\n",
        "\n",
        "\n",
        "\n",
        "  # Adjust layout for better spacing and avoid overlap\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plots\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVY87gmKO-ZC"
      },
      "outputs": [],
      "source": [
        "# combine previous plots in one\n",
        "if run_LeNet_mnist == 1:\n",
        "  # Create a figure with 3 subplots in a single row\n",
        "  fig, axs = plt.subplots(1, 1, figsize=(8, 5))\n",
        "\n",
        "  last_train_errors_mnist = {}\n",
        "  last_val_errors_mnist = {}\n",
        "\n",
        "  for spar in sparsities_mnist:\n",
        "      last_train_errors_mnist[spar] = train_errors_mnist[spar][-1]\n",
        "      last_val_errors_mnist[spar] = val_errors_mnist[spar][-1]\n",
        "\n",
        "  # Define lists for errors, titles, and labels to iterate efficiently\n",
        "  errors = [last_train_errors_mnist, last_val_errors_mnist, test_errors_mnist]\n",
        "  titles = [\"Training Error\", \"Validation Error\", \"Test Error\"]\n",
        "\n",
        "  # Loop through the three error datasets to plot them\n",
        "  for i, (error, title) in enumerate(zip(errors, titles)):\n",
        "      # Set color palette for lines and scatter points\n",
        "      line_color = 'tab:blue' if i == 0 else 'tab:orange' if i == 1 else 'tab:green'\n",
        "      scatter_color = line_color\n",
        "\n",
        "      # Plot sparsity vs. error (line)\n",
        "      #axs[i].plot(range(len(error.keys())), error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "      axs.plot(sparsities_mnist, error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "\n",
        "      # Scatter plot for better visibility\n",
        "      #axs[i].scatter(range(len(error.keys())), error.values(), color=scatter_color, s=80, zorder=5)\n",
        "      axs.scatter(sparsities_mnist, error.values(), color=scatter_color, s=80, zorder=5)\n",
        "\n",
        "      # Set y-axis limits for consistency\n",
        "      axs.set_ylim(0, 100)\n",
        "\n",
        "\n",
        "      # Add labels and title\n",
        "      axs.set_xlabel(\"Sparsity\", fontsize=12)\n",
        "      axs.set_ylabel(\"Error\", fontsize=12)\n",
        "      axs.set_title(title, fontsize=14)\n",
        "\n",
        "      # Set x-ticks with corresponding sparsities\n",
        "      #axs[i].set_xticks(range(len(error.keys())))\n",
        "      #axs.set_xticks(sparsities_mnist)\n",
        "      #axs.set_xticklabels(list(error.keys()), rotation=-90, ha=\"right\")\n",
        "\n",
        "      # Add grid for better readability\n",
        "      axs.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "\n",
        "      # Add legend with better positioning\n",
        "      axs.legend(loc='upper left', fontsize=10)\n",
        "\n",
        "\n",
        "\n",
        "  # Adjust layout for better spacing and avoid overlap\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plots\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3c8Qc0FyK8Yl"
      },
      "outputs": [],
      "source": [
        "if run_LeNet_mnist == 1:\n",
        "  # Define the number of rows and columns for the subplot grid\n",
        "  ncols = len(sparsities_mnist)\n",
        "  nrows = 1\n",
        "\n",
        "  # Initialize accuracy_list before the loop\n",
        "  accuracy_list = []\n",
        "\n",
        "  # Manually apply transforms to all images\n",
        "  images = torch.stack([test_mnist[i][0] for i in range(len(test_mnist))])\n",
        "  labels = torch.tensor([test_mnist[i][1] for i in range(len(test_mnist))])\n",
        "\n",
        "  images = images.to(device)\n",
        "\n",
        "\n",
        "  # Create a figure with subplots\n",
        "  fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(50, 50))\n",
        "\n",
        "  # Check if axes is a single Axes object and wrap it in a list if necessary\n",
        "  if ncols == 1 and nrows == 1:\n",
        "      axes = [axes]\n",
        "  else:\n",
        "      # Flatten the axes array for easy indexing if it's not a single Axes\n",
        "      axes = axes.flatten() # This will only run if axes is an ndarray (multiple subplots)\n",
        "\n",
        "  # Loop through sparsity levels and corresponding subplots\n",
        "  for idx, spar in enumerate(sparsities_mnist):\n",
        "      # Get the model for the current sparsity level\n",
        "      model = snipped_lenets[spar]\n",
        "      model.eval()\n",
        "\n",
        "      # Get predictions using the model\n",
        "      with torch.no_grad():  # Disable gradient calculations for inference\n",
        "          pred = model(images).argmax(dim=1).cpu()  # Get predictions and move to CPU\n",
        "\n",
        "      # Calculate the confusion matrix\n",
        "      cm = confusion_matrix(labels, pred)\n",
        "      disp = ConfusionMatrixDisplay(cm)\n",
        "\n",
        "      # Plot the confusion matrix in the correct subplot\n",
        "      disp.plot(cmap='Blues', values_format='d', ax=axes[idx], colorbar=False)\n",
        "\n",
        "      # Add colorbar with adjusted height, using axes[idx].figure instead of disp.ax.figure\n",
        "      cbar = axes[idx].figure.colorbar(disp.im_, ax=axes[idx], fraction=0.046, pad=0.04)\n",
        "\n",
        "      axes[idx].set_title(f\"Confusion Matrix for Sparsity: {spar}\", fontsize=16)\n",
        "\n",
        "      #increase fontsize for x and y labels and tick labels\n",
        "      axes[idx].set_xlabel(\"Predicted Labels\", fontsize=30)\n",
        "      axes[idx].set_ylabel(\"True Labels\", fontsize=30)\n",
        "      axes[idx].tick_params(axis='both', which='major', labelsize=20)\n",
        "\n",
        "      # increase fontsize of the values in the confusion matrix\n",
        "      for text in axes[idx].texts:\n",
        "        text.set_fontsize(12)\n",
        "\n",
        "  # Adjust layout to prevent overlap\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRaq-GQoOCDY"
      },
      "source": [
        "# **MAIN with CIFAR10**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCP9PvjRdF73"
      },
      "source": [
        "### Pruning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOdcu7rsOBhP"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Initialize the ResNet18 model and move it to the selected device (CPU/GPU)\n",
        "  resnet = ResNet18().to(device)\n",
        "\n",
        "  # Define different sparsity levels for cifar10 dataset experiments\n",
        "  # sparsities_cifar = [0, 0.25, 0.5, 0.75]\n",
        "\n",
        "  # Use negative log-likelihood loss\n",
        "  loss = F.nll_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrCxT0cpPohA"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  snipped_resnets = {}\n",
        "\n",
        "  total_weights_resnet = sum(p.numel() for name, p in resnet.named_parameters() if \"weight\" in name)\n",
        "  print(f\"Total weights: {total_weights_resnet}\")\n",
        "\n",
        "  # Iterate through the defined sparsity levels\n",
        "  for spar in sparsities_cifar:\n",
        "\n",
        "      # Create a deep copy of the original model to apply pruning without modifying the original\n",
        "      resnet_copy = copy.deepcopy(resnet)\n",
        "\n",
        "      if spar == 0:\n",
        "        snipped_resnets[spar] = resnet_copy\n",
        "        continue\n",
        "\n",
        "      # Compute the pruning mask using SNIP, which determines which connections to keep\n",
        "      keep_masks = SNIP(resnet, spar, train_cifar_loader, loss, device)\n",
        "\n",
        "      # Apply the computed mask to prune the copied model\n",
        "      apply_prune_mask(resnet_copy, keep_masks)\n",
        "\n",
        "      # Store the pruned model in the dictionary, indexed by its corresponding sparsity level\n",
        "      snipped_resnets[spar] = resnet_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RXOSi9_uf1yV"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  for spar, model in snipped_resnets.items():\n",
        "      plot_conv_filters(model.conv1.weight, n_rows=2, RGB=True, title=f\"Pruned Filters (conv1) with sparsity={spar}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veuF9LcS2yzr"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  for spar, model in snipped_resnets.items():\n",
        "      plot_linear_weights(model.fc.weight, title=f\"Pruned Parameters (fc) with sparsity={spar}\", manual_figsize=(14, 2))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HS0-6-uPdJ_S"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Ora1vmPVa5N",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Dictionaries to store training and validation metrics for different sparsity levels\n",
        "  train_losses_cifar = {}  # Training loss per sparsity level (list for each sparsity)\n",
        "  train_errors_cifar = {}  # Training error per sparsity level (list for each sparsity)\n",
        "  val_losses_cifar = {}    # Validation loss per sparsity level (list for each sparsity)\n",
        "  val_errors_cifar = {}    # Validation error per sparsity level (list for each sparsity)\n",
        "\n",
        "  # Iterate over pruned models at different sparsity levels\n",
        "  for spar, snipped_resnet in snipped_resnets.items():\n",
        "      # Initialize lists to store loss and error per epoch\n",
        "      train_losses_cifar[spar] = []\n",
        "      train_errors_cifar[spar] = []\n",
        "      val_losses_cifar[spar] = []\n",
        "      val_errors_cifar[spar] = []\n",
        "\n",
        "      # Initialize the optimizer with momentum\n",
        "      optimizer = optim.SGD(snipped_resnet.parameters(), lr=lr_cifar, momentum=0.9)\n",
        "\n",
        "      # Learning rate scheduler that reduces LR at specific milestones\n",
        "      scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[60, 120], gamma=0.1)\n",
        "\n",
        "      # Train and validate the model for the defined number of epochs\n",
        "      for epoch in range(1, epochs_cifar + 1):\n",
        "          # Perform training for the current epoch and store the loss and error in lists\n",
        "          train_loss, train_error = train(\n",
        "              snipped_resnet, train_cifar_loader, optimizer, loss, spar, epoch, device\n",
        "          )\n",
        "          train_losses_cifar[spar].append(train_loss)\n",
        "          train_errors_cifar[spar].append(train_error)\n",
        "\n",
        "          # Perform validation for the current epoch and store the loss and error in lists\n",
        "          val_loss, val_error = valid(\n",
        "              snipped_resnet, val_cifar_loader, loss, spar, epoch, device\n",
        "          )\n",
        "          val_losses_cifar[spar].append(val_loss)\n",
        "          val_errors_cifar[spar].append(val_error)\n",
        "\n",
        "          # Step the learning rate scheduler\n",
        "          scheduler.step()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obpxL_NSSrsA"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Loop through sparsities to plot the graphs for each sparsity value\n",
        "  for sparsity in sparsities_cifar:\n",
        "      epochs = range(1, epochs_cifar + 1)\n",
        "\n",
        "      plt.figure(figsize=(12, 5))\n",
        "\n",
        "      # Plot training and validation loss\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(epochs, train_losses_cifar[sparsity], label=\"Train Loss\", color='tab:blue',\n",
        "              linestyle='dashed', linewidth=2, marker='o', markersize=6)\n",
        "      plt.plot(epochs, val_losses_cifar[sparsity], label=\"Validation Loss\", color='tab:orange',\n",
        "              linestyle='dashed', linewidth=2, marker='s', markersize=6)\n",
        "      plt.xlabel(\"Epochs\", fontsize=12)\n",
        "      plt.ylabel(\"Loss\", fontsize=12)\n",
        "      #plt.xticks(range(1, epochs_cifar + 1, 5), fontsize=10)\n",
        "      plt.title(f\"Loss vs Epochs (Sparsity: {sparsity})\", fontsize=14)\n",
        "      plt.legend(loc='upper right', fontsize=10)\n",
        "      plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "      # Plot training and validation error\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(epochs, train_errors_cifar[sparsity], label=\"Train Error\", color='tab:blue',\n",
        "              linestyle='dashed', linewidth=2, marker='o', markersize=6)\n",
        "      plt.plot(epochs, val_errors_cifar[sparsity], label=\"Validation Error\", color='tab:orange',\n",
        "              linestyle='dashed', linewidth=2, marker='s', markersize=6)\n",
        "      plt.xlabel(\"Epochs\", fontsize=12)\n",
        "      plt.ylabel(\"Error\", fontsize=12)\n",
        "      #plt.xticks(range(1, epochs_cifar + 1), fontsize=10)\n",
        "      plt.title(f\"Error vs Epochs (Sparsity: {sparsity})\", fontsize=14)\n",
        "      plt.legend(loc='upper right', fontsize=10)\n",
        "      plt.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIBugCW83fSl"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  for spar, snipped_resnet in snipped_resnets.items():\n",
        "      torch.save(snipped_resnet, f'snipped_resnet_{spar}.pth')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ywwgpjoXjhl"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b5xxC50AXcQs"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Dictionaries to store test losses and errors for different sparsity levels\n",
        "  test_losses_cifar = {}\n",
        "  test_errors_cifar = {}\n",
        "\n",
        "  # Iterate over each pruned model in snipped_resnets\n",
        "  for spar, snipped_resnet in snipped_resnets.items():\n",
        "      # Evaluate the pruned model on the test set and store the results\n",
        "      test_losses_cifar[spar], test_errors_cifar[spar] = test(\n",
        "          snipped_resnet, test_cifar_loader, loss, spar, device\n",
        "          )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dbVHjra5X1OL"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Define figure size and 4x6 grid layout\n",
        "  # fig, axes = plt.subplots(nrows=4, ncols=6, figsize=(18, 12))\n",
        "  fig, axes = plt.subplots(nrows=len(sparsities_cifar), ncols=6, figsize=(18, 12))\n",
        "  # Reshape the axes array to have the desired 2D shape\n",
        "  axes = axes.reshape(len(sparsities_cifar), 6)\n",
        "  # Loop through the grid and plot images with predictions\n",
        "  for row in range(len(sparsities_cifar)):  # Each row represents a different sparsity level\n",
        "      sparsity = sparsities_cifar[row]  # Get the current sparsity level\n",
        "      for col in range(6):  # Six images per sparsity level\n",
        "          ax = axes[row, col]\n",
        "          sample_idx = torch.randint(len(test_cifar), size=(1,)).item()  # Randomly select an image index\n",
        "          img, label = test_cifar[sample_idx]  # Retrieve image and label\n",
        "\n",
        "          # Get model prediction\n",
        "          pred_label = snipped_resnets[sparsity](img.unsqueeze(0).to(device)).argmax(dim=1).item()\n",
        "\n",
        "          # Display the image\n",
        "          img = img * std_cifar[:, None, None] + mean_cifar[:, None, None]  # Unnormalize the image\n",
        "          ax.imshow(img.permute(1, 2, 0))  # Convert (C, H, W) to (H, W, C) for visualization\n",
        "          ax.set_title(f\"Label: {classes[label]}\\nPred: {classes[pred_label]}\", fontsize=10)\n",
        "          ax.axis(\"off\")  # Hide axis for a cleaner look\n",
        "\n",
        "      # Add sparsity level label on the left of the row\n",
        "      axes[row, 0].annotate(f\"Spar: {sparsity}\", xy=(-0.2, 0.5), xycoords='axes fraction', fontsize=12,\n",
        "                            ha='right', va='center', rotation=90, fontweight='bold')\n",
        "\n",
        "  # Adjust layout for better spacing\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yn3OAZTfYE1O"
      },
      "outputs": [],
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Create a figure with 3 subplots in a single row\n",
        "  fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "  last_train_errors_cifar = {}\n",
        "  last_val_errors_cifar = {}\n",
        "\n",
        "  for spar in sparsities_cifar:\n",
        "      last_train_errors_cifar[spar] = train_errors_cifar[spar][-1]\n",
        "      last_val_errors_cifar[spar] = val_errors_cifar[spar][-1]\n",
        "\n",
        "  # Define lists for errors, titles, and labels to iterate efficiently\n",
        "  errors = [last_train_errors_cifar, last_val_errors_cifar, test_errors_cifar]\n",
        "  titles = [\"Training Error\", \"Validation Error\", \"Test Error\"]\n",
        "\n",
        "  # Loop through the three error datasets to plot them\n",
        "  for i, (error, title) in enumerate(zip(errors, titles)):\n",
        "      # Set color palette for lines and scatter points\n",
        "      line_color = 'tab:blue' if i == 0 else 'tab:orange' if i == 1 else 'tab:green'\n",
        "      scatter_color = line_color\n",
        "\n",
        "      # Plot sparsity vs. error (line)\n",
        "      # axs[i].plot(range(len(error.keys())), error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "      axs[i].plot(sparsities_cifar, error.values(), label=title, color=line_color, linewidth=2, linestyle='-', marker='o')\n",
        "\n",
        "      # Scatter plot for better visibility\n",
        "      #axs[i].scatter(range(len(error.keys())), error.values(), color=scatter_color, s=80, zorder=5)\n",
        "      axs[i].scatter(sparsities_cifar, error.values(), color=scatter_color, s=80, zorder=5)\n",
        "\n",
        "      # Set y-axis limits for consistency\n",
        "      axs[i].set_ylim(0, 90)\n",
        "\n",
        "      # Add labels and title\n",
        "      axs[i].set_xlabel(\"Sparsity\", fontsize=12)\n",
        "      axs[i].set_ylabel(\"Error\", fontsize=12)\n",
        "      axs[i].set_title(title, fontsize=14)\n",
        "\n",
        "      # Add grid for better readability\n",
        "      axs[i].grid(True, which='both', linestyle='--', linewidth=0.5)\n",
        "\n",
        "      # Add legend with better positioning\n",
        "      axs[i].legend(loc='upper right', fontsize=10)\n",
        "\n",
        "  # Adjust layout for better spacing and avoid overlap\n",
        "  plt.tight_layout()\n",
        "\n",
        "  # Show the plots\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if run_ResNet_cifar == 1:\n",
        "  # Define the number of rows and columns for the subplot grid\n",
        "  ncols = len(sparsities_cifar)\n",
        "  nrows = 1\n",
        "\n",
        "  # Manually apply transforms to all images\n",
        "  images = torch.stack([test_cifar[i][0] for i in range(len(test_cifar))])\n",
        "  labels = torch.tensor([test_cifar[i][1] for i in range(len(test_cifar))])\n",
        "\n",
        "  # Move to GPU if needed\n",
        "  images = images.to(device)\n",
        "\n",
        "\n",
        "  # Create a figure with subplots\n",
        "  fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(30, 30))\n",
        "\n",
        "  # Check if axes is a single Axes object and wrap it in a list if necessary\n",
        "  if ncols == 1 and nrows == 1:\n",
        "      axes = [axes]\n",
        "  else:\n",
        "     axes = axes.flatten() # This will only run if axes is an ndarray (multiple subplots)\n",
        "\n",
        "  # Loop through sparsity levels and corresponding subplots\n",
        "  for idx, spar in enumerate(sparsities_cifar):\n",
        "      model = snipped_resnets[spar].to(device)\n",
        "      model.eval()\n",
        "\n",
        "      # Get predictions using the model\n",
        "      with torch.no_grad():  # Disable gradient calculations for inference\n",
        "          pred = model(images).argmax(dim=1).cpu()  # Get predictions\n",
        "\n",
        "      # Calculate the confusion matrix\n",
        "      cm = confusion_matrix(labels, pred)\n",
        "      disp = ConfusionMatrixDisplay(cm, display_labels=classes)\n",
        "\n",
        "      # Plot the confusion matrix in the correct subplot\n",
        "      disp.plot(cmap='Blues', values_format='d', ax=axes[idx], colorbar=False)\n",
        "\n",
        "      # Add colorbar with adjusted height, using axes[idx].figure instead of disp.ax.figure\n",
        "      cbar = axes[idx].figure.colorbar(disp.im_, ax=axes[idx], fraction=0.046, pad=0.04)\n",
        "\n",
        "      axes[idx].set_title(f\"Confusion Matrix for Sparsity: {spar}\", fontsize=30) # Increased title fontsize\n",
        "\n",
        "      # Increase fontsize for x and y labels and tick labels\n",
        "      axes[idx].set_xlabel(\"Predicted Label\", fontsize=20)\n",
        "      axes[idx].set_ylabel(\"True Label\", fontsize=20)\n",
        "      axes[idx].tick_params(axis='both', which='major', labelsize=16)\n",
        "\n",
        "\n",
        "      #Increase fontsize of the values in the confusion matrix\n",
        "      for text in axes[idx].texts:\n",
        "        text.set_fontsize(16)\n",
        "\n",
        "  # Adjust layout to prevent overlap\n",
        "  plt.tight_layout()\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "FrR2H_wJLFV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUm5SL6SX029"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Cm4wTH5NBwJY",
        "8ChCFAAvM1rd",
        "DbpyScdvFhCb",
        "CbbDtsnN4JnM",
        "QzTnxhtFXTFV",
        "jN-9DBVSXj01",
        "2ajB6Yvt_mMJ",
        "MKtXStLWy9y3",
        "Qj4VOtPVzBv_",
        "ZNqETkceG9Mo",
        "OaDEbvZEQAWl",
        "3ZOh5eJBQPXs",
        "M0i75adDAAEJ",
        "UqX-vdvDF4cF",
        "JsyrDtkgFxnY",
        "kwzSXX8RRZKw",
        "vbkVRW9vScGH",
        "eP88u9VySftn",
        "uNEQic0lZ0yK",
        "RCP9PvjRdF73",
        "HS0-6-uPdJ_S"
      ],
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}